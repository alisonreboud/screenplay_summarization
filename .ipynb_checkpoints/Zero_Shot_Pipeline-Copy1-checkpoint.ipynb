{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yTBP_QYuu6tc"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install transformers==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "TiU_ES5tzpMH"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "spkccRiv0CB3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier = pipeline(\"zero-shot-classification\", device=1) # to utilize GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWiovVJG9ei_"
   },
   "source": [
    "We can use this pipeline by passing in a sequence and a list of candidate labels. The pipeline assumes by default that only one of the candidate labels is true, returning a list of scores for each label which add up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s05e10', 's03e03', 's01e19', 's01e23', 's02e15', 's02e01', 's05e22', 's02e09', 's05e21', 's04e23', 's04e09', 's05e12', 's03e12', 's05e03', 's04e22', 's03e21', 's02e04', 's03e19', 's04e14', 's04e06', 's01e07', 's04e21', 's05e17', 's03e08', 's04e10', 's04e05', 's05e05', 's05e06', 's01e20', 's04e15', 's02e06', 's01e08', 's04e12', 's05e08', 's03e05', 's02e10', 's05e13', 's03e11', 's01e13']\n"
     ]
    }
   ],
   "source": [
    "path_screenplays_scenes='coref/csi-corpus/screenplay_summarization/scene_level_n_aspects'\n",
    "eps=[]\n",
    "\n",
    "\n",
    "for ep in listdir(path_screenplays_scenes):\n",
    "    annotated_scenes=pd.read_csv(path_screenplays_scenes+'/'+ep)\n",
    "    eps.append(ep.split('.csv')[0])\n",
    "    \n",
    "    \n",
    "print(eps)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "hkfE6NRA0Dzy",
    "outputId": "8b3f9e37-3e46-4b25-813b-c5fa7bbc3c97"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_results(df, classifier, topic_labels):\n",
    "    df['topic'] = None\n",
    "    df['score'] = None\n",
    "    \n",
    "    for i in tqdm(range(0, df.shape[0])):\n",
    "        text = df.loc[i, 'scene_text']\n",
    "        if text is not None:\n",
    "            result = classifier(text, topic_labels,multi_class=False)\n",
    "            #df.loc[i, 'topic'] = str(str(result['labels'][0])+\"+\"+str(result['labels'][1]))\n",
    "            #df.loc[i, 'score'] = str(str(result['scores'][0])+\"+\"+str(result['scores'][1]))\n",
    "            df.loc[i, 'topic'] = result['labels'][0]\n",
    "            df.loc[i, 'score'] = result['scores'][0]\n",
    "            #if result['labels'][0]=='kill':\n",
    "                #df.loc[i, 'score_hf'] = result['scores'][0]\n",
    "            #else:\n",
    "                #df.loc[i, 'score_hf'] = -1\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_results_several_binary(df, classifier, topic_labels):\n",
    "    df['topic'] = None\n",
    "    df['score'] = 0\n",
    "    \n",
    "    for i in tqdm(range(0, df.shape[0])):\n",
    "        text = df.loc[i, 'scene_text']\n",
    "        if text is not None:\n",
    "            for j in topic_labels:\n",
    "                result = classifier(text,j,multi_class=False)\n",
    "            #df.loc[i, 'topic'] = str(str(result['labels'][0])+\"+\"+str(result['labels'][1]))\n",
    "            #df.loc[i, 'score'] = str(str(result['scores'][0])+\"+\"+str(result['scores'][1]))\n",
    "                df.loc[i, 'score']=df.loc[i, 'score'] + result['scores'][0]\n",
    "            #if result['labels'][0]=='kill':\n",
    "                #df.loc[i, 'score_hf'] = result['scores'][0]\n",
    "            #else:\n",
    "                #df.loc[i, 'score_hf'] = -1\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eps=['s05e10']\n",
    "### To read score obtained with Trecvid method\n",
    "method_used='tfidf'\n",
    "for ep in eps:\n",
    "    df=pd.read_csv(ep+'_'+method_used+'_similarity.csv')\n",
    "    #print(df.columns)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:16<00:00,  2.12it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      " 41%|████      | 16/39 [00:06<00:09,  2.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-5cbf09e53d5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#candidate_labels=[\"thought-provoking\",\"storytelling\",\"suspenseful\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mfirst_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_results_several_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcandidate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#first_results=df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfirst_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction_class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-147-f9c6f3068ab8>\u001b[0m in \u001b[0;36mget_results_several_binary\u001b[0;34m(df, classifier, topic_labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;31m#df.loc[i, 'topic'] = str(str(result['labels'][0])+\"+\"+str(result['labels'][1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m#df.loc[i, 'score'] = str(str(result['scores'][0])+\"+\"+str(result['scores'][1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sequences, candidate_labels, hypothesis_template, multi_class)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \"\"\"\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m         \u001b[0mnum_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0mcandidate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_and_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/pipelines.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, inputs, return_tensors)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_outputs, decoder_input_ids, decoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m         )\n\u001b[1;32m   1200\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# last hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, encoder_outputs, decoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m             )\n\u001b[1;32m    921\u001b[0m         \u001b[0;31m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOuput when return_dict=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# check attention mask and invert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvert_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bart.py\u001b[0m in \u001b[0;36minvert_mask\u001b[0;34m(attention_mask)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;34m\"\"\"Turns 1->0, 0->1, False->True, True-> False\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f1_scores=[]\n",
    "\n",
    "for ep in eps:\n",
    "    #print(ep)\n",
    "    #df=pd.read_csv(ep+'_'+method_used+'_similarity.csv')\n",
    "    df=pd.read_csv(path_screenplays_scenes+'/'+ep+'.csv')\n",
    "    #candidate_labels=['Crime','Drama','Mystery','Thriller']\n",
    "    #candidate_labels=['crime lab','police','crime scene investigation','las vegas nevada','detective','forensics','forensic science','crime scene investigator','police procedural','police detective']\n",
    "    candidate_labels=['crime scene', 'victim', 'death cause', 'perpetrator', 'evidence', 'motive']\n",
    "    #candidate_labels=['body farm','carpet beetle','house fire','explosion','maggot']\n",
    "    \n",
    "    #candidate_labels=[\"thought-provoking\",\"storytelling\",\"suspenseful\"]\n",
    "    first_results=get_results_several_binary(df,classifier,candidate_labels)\n",
    "    #first_results=df\n",
    "    first_results['prediction_class']=0\n",
    "    first_results=first_results.sort_values(by=['score'],ascending=False)\n",
    "    first_results['prediction_class'].iloc[0:len(first_results[first_results.in_summary==1])]=1\n",
    "    #print(first_results[['aspects']])\n",
    "    #first_results['prediction_class'].iloc[0:int(0.4*len(df.index))]=1\n",
    "    print(first_results)\n",
    "    f1_scores.append(f1_score(first_results.in_summary, first_results.prediction_class))\n",
    "    \n",
    "    \n",
    "print(np.mean(f1_scores)) \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4369960042471354\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(f1_scores))\n",
    "\n",
    "print(len(f1_scores))\n",
    "\n",
    "#first_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #action, drama, horror and romance.\n",
    "    #candidate_labels=['action', 'crime','romance','comedy']\n",
    "    #candidate_labels=['action', 'crime','romance','comedy']\n",
    "    #candidate_labels=joy,sadness, anger,fear, trust,distrust, surprise,anticipation\n",
    "    #candidate_labels=['surprise','anticipation']\n",
    "    #candidate_labels=['mystic']\n",
    "    \n",
    "    #candidate_labels=['Action','Animation','Biography','Comedy','Crime','Drama','Family','Fantasy','Horror','Mystery','Romance','SciFi','Thriller']\n",
    "    #candidate_labels=['Action','Biography','Comedy','Crime','Drama','Family','Fantasy','Horror','Romance','SciFi','Thriller']\n",
    "    #candidate_labels=['anger', 'sadness','joy',feat]\n",
    "    #candidate_labels = ['Crime scene', 'Victim', 'Death cause', 'Perpetrator', 'Evidence', 'Motive']\n",
    "    #candidate_labels=['crime scene', 'victim', 'death cause', 'perpetrator', 'evidence', 'motive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"f1_scores=[]\\n#eps=['s05e10']\\nfor ep in eps:\\n    print(ep)\\n    df=pd.read_csv(ep+'_'+method_used+'_similarity.csv')\\n    sequence=df.scene_text\\n    #candidate_labels = ['Crime scene', 'Victim', 'Death cause', 'Perpetrator', 'Evidence', 'Motive']\\n    #candidate_labels=['crime scene', 'victim', 'death cause', 'perpetrator', 'evidence', 'motive']\\n    #candidate_labels=['kill']\\n    #action, drama, horror and romance.\\n    #candidate_labels=['action', 'crime','romance','comedy']\\n    #candidate_labels=['action', 'crime','romance','comedy']\\n    #candidate_labels=joy,sadness, anger,fear, trust,distrust, surprise,anticipation\\n    candidate_labels=['surprise','anticipation']\\n    #candidate_labels=['thought-provoking']\\n    \\n    #candidate_labels=['Action','Animation','Biography','Comedy','Crime','Drama','Family','Fantasy','Horror','Mystery','Romance','SciFi','Thriller']\\n    #candidate_labels=['Action','Biography','Comedy','Crime','Drama','Family','Fantasy','Horror','Romance','SciFi','Thriller']\\n    #candidate_labels=['anger', 'sadness','joy',feat]\\n    first_results=get_results(df,classifier,candidate_labels)\\n    first_results[['prediction_score','score_hf']]=MinMaxScaler().fit_transform(first_results[['prediction_score','score_hf']])\\n                  \\n    #print(first_results)\\n    first_results['sum_score']=0.5*first_results['score_hf']+0.5*first_results['prediction_score']\\n    #print(first_results['sum_score'])\\n    #ranked=first_results[first_results.topic=='murder'].sort_values(by=['score'],ascending=False)\\n    first_results['prediction_class']=0\\n    #ranked['prediction_class']=0\\n    #ranked['prediction_class'].iloc[0:len(first_results[first_results.in_summary==1])]=1\\n    #predicted_pos= ranked['scene_id'][ranked['prediction_class']==1]\\n    #predicted_pos=list(predicted_pos)\\n    #print(predicted_pos)\\n    #first_results=first_results.sort_values(by=['sum_score'],ascending=False)\\n    first_results=first_results.sort_values(by=['score_hf'],ascending=False)\\n    first_results['prediction_class'].iloc[0:len(first_results[first_results.in_summary==1])]=1\\n    #first_results.to_csv('combined_scores_kill'+ep+'.csv',index=None)\\n    #first_results.loc[first_results['scene_id'].isin(predicted_pos), 'prediction_huggingface'] = 1 \\n    #print(first_results)\\n    f1_scores.append(f1_score(first_results.in_summary, first_results.prediction_class))\\n    \\n    \\n    \\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###FOR SCORE COMBINATION\n",
    "\"\"\"f1_scores=[]\n",
    "#eps=['s05e10']\n",
    "for ep in eps:\n",
    "    print(ep)\n",
    "    df=pd.read_csv(ep+'_'+method_used+'_similarity.csv')\n",
    "    sequence=df.scene_text\n",
    "    #candidate_labels = ['Crime scene', 'Victim', 'Death cause', 'Perpetrator', 'Evidence', 'Motive']\n",
    "    #candidate_labels=['crime scene', 'victim', 'death cause', 'perpetrator', 'evidence', 'motive']\n",
    "    #candidate_labels=['kill']\n",
    "    #action, drama, horror and romance.\n",
    "    #candidate_labels=['action', 'crime','romance','comedy']\n",
    "    #candidate_labels=['action', 'crime','romance','comedy']\n",
    "    #candidate_labels=joy,sadness, anger,fear, trust,distrust, surprise,anticipation\n",
    "    candidate_labels=['surprise','anticipation']\n",
    "    #candidate_labels=['thought-provoking']\n",
    "    \n",
    "    #candidate_labels=['Action','Animation','Biography','Comedy','Crime','Drama','Family','Fantasy','Horror','Mystery','Romance','SciFi','Thriller']\n",
    "    #candidate_labels=['Action','Biography','Comedy','Crime','Drama','Family','Fantasy','Horror','Romance','SciFi','Thriller']\n",
    "    #candidate_labels=['anger', 'sadness','joy',feat]\n",
    "    first_results=get_results(df,classifier,candidate_labels)\n",
    "    first_results[['prediction_score','score_hf']]=MinMaxScaler().fit_transform(first_results[['prediction_score','score_hf']])\n",
    "                  \n",
    "    #print(first_results)\n",
    "    first_results['sum_score']=0.5*first_results['score_hf']+0.5*first_results['prediction_score']\n",
    "    #print(first_results['sum_score'])\n",
    "    #ranked=first_results[first_results.topic=='murder'].sort_values(by=['score'],ascending=False)\n",
    "    first_results['prediction_class']=0\n",
    "    #ranked['prediction_class']=0\n",
    "    #ranked['prediction_class'].iloc[0:len(first_results[first_results.in_summary==1])]=1\n",
    "    #predicted_pos= ranked['scene_id'][ranked['prediction_class']==1]\n",
    "    #predicted_pos=list(predicted_pos)\n",
    "    #print(predicted_pos)\n",
    "    #first_results=first_results.sort_values(by=['sum_score'],ascending=False)\n",
    "    first_results=first_results.sort_values(by=['score_hf'],ascending=False)\n",
    "    first_results['prediction_class'].iloc[0:len(first_results[first_results.in_summary==1])]=1\n",
    "    #first_results.to_csv('combined_scores_kill'+ep+'.csv',index=None)\n",
    "    #first_results.loc[first_results['scene_id'].isin(predicted_pos), 'prediction_huggingface'] = 1 \n",
    "    #print(first_results)\n",
    "    f1_scores.append(f1_score(first_results.in_summary, first_results.prediction_class))\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-33e6f88f7c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aspects'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'in_summary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'prediction_class'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sum_score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'prediction_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_results' is not defined"
     ]
    }
   ],
   "source": [
    "#print(first_results[first_results.in_summary==1])\n",
    "\n",
    "\n",
    "print(first_results[['aspects','in_summary','topic','score','prediction_class','sum_score','prediction','prediction_score']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45383506473297075\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(f1_scores))\n",
    "\n",
    "print(len(f1_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s05e10', 's03e03', 's01e19', 's01e23', 's02e15', 's02e01', 's05e22', 's02e09', 's05e21', 's04e23', 's04e09', 's05e12', 's03e12', 's05e03', 's04e22', 's03e21', 's02e04', 's03e19', 's04e14', 's04e06', 's01e07', 's04e21', 's05e17', 's03e08', 's04e10', 's04e05', 's05e05', 's05e06', 's01e20', 's04e15', 's02e06', 's01e08', 's04e12', 's05e08', 's03e05', 's02e10', 's05e13', 's03e11', 's01e13']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5102968754727771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "f1_scores_bis=[]\n",
    "#eps=[]\n",
    "\n",
    "print(eps)\n",
    "\n",
    "\n",
    "for ep in eps:\n",
    "    df=pd.read_csv('combined_scores_kill'+ep+'.csv')\n",
    "    #print(df)\n",
    "    #print(df)\n",
    "    #df['max']=df[[\"prediction_score\", \"score_hf\"]].max(axis=1)\n",
    "    df['max']=0.5*df['score_hf']+0.5*df['prediction_score']\n",
    "    df=df.sort_values(by=['prediction_score'],ascending=False)\n",
    "    df['prediction_class']=0\n",
    "    df['prediction_class'].iloc[0:len(df[df.in_summary==1])]=1\n",
    "    #print(df[['in_summary','topic','score_hf','prediction_class','sum_score','prediction','prediction_score','max']])\n",
    "    \n",
    "            \n",
    "            \n",
    "    #first_results.to_csv('combined_scores'+ep+'.csv')\n",
    "    #first_results.loc[first_results['scene_id'].isin(predicted_pos), 'prediction_huggingface'] = 1 \n",
    "    #print(first_results)\n",
    "    df=df.sort_values(by=['score_hf'],ascending=False)\n",
    "    df['prediction_class'].iloc[0:len(df[df.in_summary==1])]=1\n",
    "    #first_results.loc[first_results['scene_id'].isin(predicted_pos), 'prediction_huggingface'] = 1 \n",
    "    #print(first_results0\n",
    "    f1_scores_bis.append(f1_score(df.in_summary, df.prediction_class))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "print(np.mean(f1_scores_bis))\n",
    "\n",
    "#print(len(f1_scores))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-c61821b32eb2>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-c61821b32eb2>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    first_results[first_results.topic=='Crime'].sort_values(by=['score'],ascending=False)[]\u001b[0m\n\u001b[0m                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1_scores_emotions=[]\n",
    "for ep in eps:\n",
    "    df=pd.read_csv(ep+'_'+method_used+'_similarity.csv')\n",
    "    sequence=df.scene_text\n",
    "    #candidate_labels = ['Crime scene', 'Victim', 'Death cause', 'Perpetrator', 'Evidence', 'Motive']\n",
    "    candidate_labels=['anger', 'anticipation', 'joy', 'trust', 'fear', 'surprise', 'sadness', 'disgust']\n",
    "    first_results=get_results(df,classifier,candidate_labels)   \n",
    "    first_results['prediction_class']=0\n",
    "    first_results[first_results.topic=='Crime'].sort_values(by=['score'],ascending=False)[]\n",
    "\n",
    "    ranked['prediction_class'].iloc[0:len(first_results[first_results.in_summary==1])]=1\n",
    "    ranked.to_csv('murder_hum_class'+ep+'.csv')\n",
    "    print(ranked)\n",
    "    f1_scores_emotions.append(f1_score(ranked.in_summary, ranked.prediction_class))\n",
    "   \n",
    "classifier(sequence, candidate_labels, multi_class=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "s04e09\n",
      "[0.19999999999999998, 0.2857142857142857, 0.28571428571428575, 0.3157894736842105, 0.3333333333333333, 0.36363636363636365, 0.4, 0.4, 0.4285714285714285, 0.43478260869565216, 0.45454545454545453, 0.47058823529411764, 0.5, 0.5, 0.5, 0.5, 0.5000000000000001, 0.5714285714285714, 0.6, 0.6, 0.6, 0.6153846153846153, 0.6153846153846153, 0.6153846153846153, 0.631578947368421, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.7000000000000001, 0.7142857142857143, 0.7142857142857143, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7499999999999999, 0.7499999999999999, 0.8571428571428571, 1.0]\n",
      "   Unnamed: 0  Unnamed: 0.1  scene_id  \\\n",
      "0           8             8         8   \n",
      "1          30            30        30   \n",
      "\n",
      "                                          scene_text  in_summary      aspects  \\\n",
      "0  [' ( Scene opens on a close up of two prints ,...           1  Death cause   \n",
      "1  [' ( CATHERINE puts the bagged vice grips on t...           1       Motive   \n",
      "\n",
      "   prediction  aspect?   topic     score  prediction_class  \n",
      "0           0        1  Murder  0.837703                 1  \n",
      "1           1        1  Murder  0.551375                 1  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sorted_f1 = f1_scores.copy()\n",
    "sorted_f1.sort()\n",
    "print(f1_scores[10])\n",
    "print(eps[10])\n",
    "ep=eps[10]\n",
    "print(sorted_f1)\n",
    "df=pd.read_csv('murder_hum_class'+ep+'.csv')\n",
    "\n",
    "#print(df.scene_text[df.in_summary==0].iloc[4])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s05e10\n",
      "Index(['Unnamed: 0', 'scene_id', 'scene_text', 'in_summary', 'aspects',\n",
      "       'prediction_score', 'prediction', 'aspect?'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_all=pd.DataFrame(columns=['Unnamed: 0', 'scene_id', 'scene_text', 'in_summary', 'aspects',\n",
    "       'prediction_score', 'prediction', 'aspect?'])\n",
    "f1_scores=[]\n",
    "eps=['s05e10']\n",
    "for ep in eps:\n",
    "    print(ep)\n",
    "    df=pd.read_csv(ep+'_'+method_used+'_similarity.csv')\n",
    "    print(df.columns)\n",
    "    df_all=df_all.append(df)\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s05e10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [03:18<00:00,  5.84s/it]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s05e10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [03:18<00:00,  5.85s/it]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s03e03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [04:01<00:00,  6.18s/it]\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s01e19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:31<00:00,  5.88s/it]\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s01e23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [04:05<00:00,  6.15s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s02e15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [03:24<00:00,  4.36s/it]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s02e01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [03:42<00:00,  5.31s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s05e22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [03:17<00:00,  6.18s/it]\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s02e09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:55<00:00,  5.01s/it]\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s05e21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [03:46<00:00,  6.13s/it]\n",
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s04e23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:00<00:00,  3.75s/it]\n",
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s04e09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [03:29<00:00,  6.76s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s05e12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [03:23<00:00,  6.37s/it]\n",
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s03e12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [03:17<00:00,  4.12s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thought-provoking\n",
      "s05e03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [00:30<04:15,  8.82s/it]"
     ]
    }
   ],
   "source": [
    "for ep in listdir(path_screenplays_scenes):\n",
    "    annotated_scenes=pd.read_csv(path_screenplays_scenes+'/'+ep)\n",
    "    eps.append(ep.split('.csv')[0])\n",
    "    \n",
    "tags_entire_episode=[]\n",
    "\n",
    "for ep in eps:\n",
    "    print(ep)\n",
    "    df=pd.read_csv(ep+'_'+method_used+'_similarity.csv')\n",
    "    #candidate_labels = ['Crime scene', 'Victim', 'Death cause', 'Perpetrator', 'Evidence', 'Motive']\n",
    "    #candidate_labels=['crime scene', 'victim', 'death cause', 'perpetrator', 'evidence', 'motive']\n",
    "    #candidate_labels=['kill','love']\n",
    "    #action, drama, horror and romance.\n",
    "    #candidate_labels=['action', 'crime','romance','comedy','murder']\n",
    "    #candidate_labels=['action', 'crime','romance','comedy']\n",
    "    #candidate_labels=joy,sadness, anger,fear, trust,distrust, surprise,anticipation\n",
    "    candidate_labels=['murder','violence', 'flashback', 'romantic', 'cult', 'revenge', 'psychedelic', 'comedy', 'suspenseful', 'good_versus_evil', 'humor', 'satire', 'entertaining', 'neo noir', 'action', 'sadist', 'insanity', 'tragedy', 'fantasy', 'paranormal', 'boring', 'mystery', 'horror', 'melodrama', 'cruelty', 'gothic', 'dramatic', 'dark', 'atmospheric', 'storytelling', 'sci-fi', 'psychological', 'historical', 'absurd', 'prank', 'sentimental', 'philosophical', 'avant garde', 'bleak', 'alternate reality', 'depressing', 'plot twist', 'realism', 'cute', 'stupid', 'intrigue', 'pornographic', 'home movie', 'haunting', 'historical fiction', 'allegory', 'adult comedy', 'thought-provoking', 'inspiring', 'anti war', 'comic', 'brainwashing', 'alternate history', 'queer', 'clever', 'claustrophobic', 'whimsical', 'feel-good', 'blaxploitation', 'western', 'grindhouse film', 'magical realism', 'suicidal', 'autobiographical', 'christian film', 'non fiction']\n",
    "    df['topic'] = None\n",
    "    for i in tqdm(range(0, df.shape[0])):\n",
    "        result= classifier(text, 'murder')\n",
    "        df.loc[i, 'topic']='bigoudi'\n",
    "        text = df.loc[i, 'scene_text']\n",
    "        if text is not None:\n",
    "            for j in candidate_labels:\n",
    "                result_provisoire = classifier(text, j)\n",
    "                #print(result_provisoire['scores'][0].type)\n",
    "                #print(result_provisoire['scores'][0])\n",
    "                #print(result['scores'][0])\n",
    "                if result_provisoire['scores'][0]>result['scores'][0]:\n",
    "                    result['scores']=result_provisoire['scores']\n",
    "                    #print(result['scores'])\n",
    "                    df.loc[i, 'topic'] = result_provisoire['labels'][0]\n",
    "                    #print(df.loc[i, 'topic'])                   \n",
    "            #print(result['labels'][0])\n",
    "    #print(df.loc[i, 'topic'])\n",
    "    print(df['topic'].value_counts().argmax())\n",
    "    tags_entire_episode.append(df['topic'].value_counts().argmax())\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    sequence=df.scene_text\n",
    "    #candidate_labels = ['Crime scene', 'Victim', 'Death cause', 'Perpetrator', 'Evidence', 'Motive']\n",
    "    #candidate_labels=['crime scene', 'victim', 'death cause', 'perpetrator', 'evidence', 'motive']\n",
    "    #candidate_labels=['kill']\n",
    "    #action, drama, horror and romance.\n",
    "    #candidate_labels=['action', 'crime','romance','comedy']\n",
    "    #candidate_labels=['action', 'crime','romance','comedy']\n",
    "    #candidate_labels=joy,sadness, anger,fear, trust,distrust, surprise,anticipation\n",
    "    candidate_labels=['surprise','anticipation']\n",
    "    \n",
    "    #candidate_labels=['Action','Animation','Biography','Comedy','Crime','Drama','Family','Fantasy','Horror','Mystery','Romance','SciFi','Thriller']\n",
    "    #candidate_labels=['Action','Biography','Comedy','Crime','Drama','Family','Fantasy','Horror','Romance','SciFi','Thriller']\n",
    "    #candidate_labels=['anger', 'sadness','joy',feat]\n",
    "    first_results=get_results(df,classifier,candidate_labels)\n",
    "    first_results[['prediction_score','score_hf']]=MinMaxScaler().fit_transform(first_results[['prediction_score','score_hf']])\n",
    "                  \n",
    "    #print(first_results)\n",
    "    first_results['sum_score']=0.5*first_results['score_hf']+0.5*first_results['prediction_score']\n",
    "    #print(first_results['sum_score'])\n",
    "    #ranked=first_results[first_results.topic=='murder'].sort_values(by=['score'],ascending=False)\n",
    "    first_results['prediction_class']=0\n",
    "    #ranked['prediction_class']=0\n",
    "    #ranked['prediction_class'].iloc[0:len(first_results[first_results.in_summary==1])]=1\n",
    "    #predicted_pos= ranked['scene_id'][ranked['prediction_class']==1]\n",
    "    #predicted_pos=list(predicted_pos)\n",
    "    #print(predicted_pos)\n",
    "    #first_results=first_results.sort_values(by=['sum_score'],ascending=False)\n",
    "    first_results=first_results.sort_values(by=['score_hf'],ascending=False)\n",
    "    first_results['prediction_class'].iloc[0:len(first_results[first_results.in_summary==1])]=1\n",
    "    #first_results.to_csv('combined_scores_kill'+ep+'.csv',index=None)\n",
    "    #first_results.loc[first_results['scene_id'].isin(predicted_pos), 'prediction_huggingface'] = 1 \n",
    "    #print(first_results)\n",
    "    f1_scores.append(f1_score(first_results.in_summary, first_results.prediction_class))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGXwxxyn9nOC"
   },
   "source": [
    "To do multi-class classification, simply pass `multi_class=True`. In this case, the scores will be independent, but each will fall between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "ZvZeVb2h5RX0",
    "outputId": "9ba085bf-4c52-4011-9c51-3a0adeddd3a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['politics', 'elections', 'public health', 'economics'],\n",
       " 'scores': [0.972069501876831,\n",
       "  0.967610776424408,\n",
       "  0.03248710557818413,\n",
       "  0.0061644683592021465],\n",
       " 'sequence': 'Who are you voting for in 2020?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Who are you voting for in 2020?\"\n",
    "candidate_labels = [\"politics\", \"public health\", \"economics\", \"elections\"]\n",
    "\n",
    "classifier(sequence, candidate_labels, multi_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLLeDT1r9-yQ"
   },
   "source": [
    "Here's an example of sentiment classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "f7AF53Wl5f8W",
    "outputId": "50a52076-7d2b-4ce0-b95f-c9cf9a13b361"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['negative', 'positive'],\n",
       " 'scores': [0.9916268587112427, 0.00837317667901516],\n",
       " 'sequence': 'I hated this movie. The acting sucked.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"I hated this movie. The acting sucked.\"\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "\n",
    "classifier(sequence, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSoBpCpV6k4s"
   },
   "source": [
    "So how does this method work?\n",
    "\n",
    "The underlying model is trained on the task of Natural Language Inference (NLI), which takes in two sequences and determines whether they contradict each other, entail each other, or neither.\n",
    "\n",
    "This can be adapted to the task of zero-shot classification by treating the sequence which we want to classify as one NLI sequence (called the premise) and turning a candidate label into the other (the hypothesis). If the model predicts that the constructed premise _entails_ the hypothesis, then we can take that as a prediction that the label applies to the text. Check out [this blog post](https://joeddav.github.io/blog/2020/05/29/ZSL.html) for a more detailed explanation.\n",
    "\n",
    "By default, the pipeline turns labels into hypotheses with the template `This example is {class_name}.`. This works well in many settings, but you can also customize this for your specific setting. Let's add another review to our above sentiment classification example that's a bit more challenging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "5yLx3pRr5xQA",
    "outputId": "6420fb46-9aeb-4055-8ab6-fdc5eb822a60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': ['negative', 'positive'],\n",
       "  'scores': [0.9916267991065979, 0.008373182266950607],\n",
       "  'sequence': 'I hated this movie. The acting sucked.'},\n",
       " {'labels': ['negative', 'positive'],\n",
       "  'scores': [0.8148515820503235, 0.1851484179496765],\n",
       "  'sequence': \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\n",
    "    \"I hated this movie. The acting sucked.\",\n",
    "    \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"\n",
    "]\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "\n",
    "classifier(sequences, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfrpyGWM782R"
   },
   "source": [
    "The second example is a bit harder. Let's see if we can improve the results by using a hypothesis template which is more specific to the setting of review sentiment analysis. Instead of the default, `This example is {}.`, we'll use, `The sentiment of this review is {}.` (where `{}` is replaced with the candidate class name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "kqx5hp7X8XNA",
    "outputId": "69c6e083-f3dc-41db-fca5-d96a3541f1fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': ['negative', 'positive'],\n",
       "  'scores': [0.9890093207359314, 0.010990672744810581],\n",
       "  'sequence': 'I hated this movie. The acting sucked.'},\n",
       " {'labels': ['positive', 'negative'],\n",
       "  'scores': [0.9581228494644165, 0.0418771356344223],\n",
       "  'sequence': \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\n",
    "    \"I hated this movie. The acting sucked.\",\n",
    "    \"This movie didn't quite live up to my high expectations, but overall I still really enjoyed it.\"\n",
    "]\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "hypothesis_template = \"The sentiment of this review is {}.\"\n",
    "\n",
    "classifier(sequences, candidate_labels, hypothesis_template=hypothesis_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iArbRAe781-_"
   },
   "source": [
    "By providing a more precise hypothesis template, we are able to see a more accurate classification of the second review.\n",
    "\n",
    "> Note that sentiment classification is used here just as an illustrative example. The [Hugging Face Model Hub](https://huggingface.co/models?filter=text-classification) has a number of models trained specifically on sentiment tasks which can be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxUTOnllSH4w"
   },
   "source": [
    "#### Update: Zero-shot classification in 100 languages\n",
    "\n",
    "Interested in using the pipeline for languages other than English? We've trained a cross-lingual model on top of XLM RoBERTa which you can use by passing `model='joeddav/xlm-roberta-large-xnli'` when creating the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siZhFPekSN7t"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model='joeddav/xlm-roberta-large-xnli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrcljZ75UxKN"
   },
   "source": [
    "You can use it with any combination of languages. For example, let's classify a Russian sentence with English candidate labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "gBJyFwC2TwGv",
    "outputId": "5e683b8a-2e9f-46c2-95f9-04559bed04ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['politics', 'Europe', 'public health'],\n",
       " 'scores': [0.9048484563827515, 0.05722189322113991, 0.03792969882488251],\n",
       " 'sequence': 'За кого вы голосуете в 2020 году?'}"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"За кого вы голосуете в 2020 году?\" # translation: \"Who are you voting for in 2020?\"\n",
    "candidate_labels = [\"Europe\", \"public health\", \"politics\"]\n",
    "\n",
    "classifier(sequence, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9hGVMsrVI8S"
   },
   "source": [
    "Now let's do the same but with the labels in French:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "0xKYBOLYVeNJ",
    "outputId": "a8066bb5-9e95-4f80-d77b-9753cc4c4be3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['politique', 'Europe', 'santé publique'],\n",
       " 'scores': [0.9726154804229736, 0.017128489911556244, 0.010256024077534676],\n",
       " 'sequence': 'За кого вы голосуете в 2020 году?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"За кого вы голосуете в 2020 году?\" # translation: \"Who are you voting for in 2020?\"\n",
    "candidate_labels = [\"Europe\", \"santé publique\", \"politique\"]\n",
    "\n",
    "classifier(sequence, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHURJUPCVgGP"
   },
   "source": [
    "As we discussed in the last section, the default hypothesis template is the English, `This text is {}.`. If you are working strictly within one language, it may be worthwhile to translate this to the language you are working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "ZCtTclt7VpMv",
    "outputId": "87c768b3-2193-4164-d993-0ee9c9eec3ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['política', 'Europa', 'salud pública'],\n",
       " 'scores': [0.9109585881233215, 0.05954807624220848, 0.029493311420083046],\n",
       " 'sequence': '¿A quién vas a votar en 2020?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"¿A quién vas a votar en 2020?\"\n",
    "candidate_labels = [\"Europa\", \"salud pública\", \"política\"]\n",
    "hypothesis_template = \"Este ejemplo es {}.\"\n",
    "\n",
    "classifier(sequence, candidate_labels, hypothesis_template=hypothesis_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQyVNE2fTDVs"
   },
   "source": [
    "The model is fine-tuned on XNLI which includes 15 languages: Arabic, Bulgarian, Chinese, English, French, German, Greek, Hindi, Russian, Spanish, Swahili, Thai, Turkish, Urdu, and Vietnamese. The base model is trained on 85 more, so the model will work to some degree for any of those in the XLM RoBERTa training corpus (see the full list in appendix A of the [XLM Roberata paper](https://arxiv.org/abs/1911.02116)).\n",
    "\n",
    "See the [model page](https://huggingface.co/joeddav/xlm-roberta-large-xnli) for more."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "🤗 Zero Shot Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
